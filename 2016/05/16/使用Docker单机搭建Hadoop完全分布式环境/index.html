<html><head><meta name="generator" content="Hexo 3.9.0"><title>使用Docker单机搭建Hadoop完全分布式环境</title><meta name="keywords" content="KDF5000, OpenHex"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><link href="/css/main.css?v=3" rel="stylesheet" type="text/css"><script src="/js/util.js"></script><script>isMobile()?loadjscssfile("../css/mobile.css","css"):loadjscssfile("../css/desktop.css","css")</script><link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Atom feed"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=3"></head><body><h2 class="title">使用Docker单机搭建Hadoop完全分布式环境</h2><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#0x01-Hydra-hadoop"><span class="toc-text">0x01 Hydra-hadoop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#0x02-项目目录"><span class="toc-text">0x02 项目目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#0x03-使用说明"><span class="toc-text">0x03 使用说明</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#0x01-clone"><span class="toc-text">0x01 clone</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#0x02-创建镜像"><span class="toc-text">0x02 创建镜像</span></a></li></ol></li></ol><h4 id="0x01-Hydra-hadoop"><a href="#0x01-Hydra-hadoop" class="headerlink" title="0x01 Hydra-hadoop"></a>0x01 Hydra-hadoop</h4><p>使用docker在单机部署hadoop和hbase的分布式环境，本项目具有一下特征：</p><ul><li>使用serf和dnsmasq 作为集群节点管理和dns解析</li><li>可以自定义集群hadoop和hbase的配置，配置完后只需重新build镜像即可</li><li>ssh远程登录集群节点容器</li></ul><p><strong>项目地址</strong>：<a href="https://github.com/KDF5000/hydra-hadoop" target="_blank" rel="noopener">https://github.com/KDF5000/hydra-hadoop</a></p><h4 id="0x02-项目目录"><a href="#0x02-项目目录" class="headerlink" title="0x02 项目目录"></a>0x02 项目目录</h4><p><strong>serf-dnsmasq</strong>： serf和dnsmasq服务，用于管理集群节点的退出和添加，dnsmasq用于dns的解析<br><strong>hadoop-fake:</strong> 实现一个伪分布式的hadoop环境<br><strong>hadoop-hydra:</strong> 基于<code>hadoop-fake</code>实现一个完全分布式的集群环境，master和slave均使用该镜像</p><h4 id="0x03-使用说明"><a href="#0x03-使用说明" class="headerlink" title="0x03 使用说明"></a>0x03 使用说明</h4><p>默认本机已经安装了docker环境和git工具</p><h5 id="0x01-clone"><a href="#0x01-clone" class="headerlink" title="0x01 clone"></a>0x01 clone</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/KDF5000/hydra-hadoop</span><br></pre></td></tr></table></figure><h5 id="0x02-创建镜像"><a href="#0x02-创建镜像" class="headerlink" title="0x02 创建镜像"></a>0x02 创建镜像</h5><p>按照下面的顺序执行相应操作</p><ul><li>进入serf-dnsmasq目录，执行<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker build -t=&quot;kdf5000/serf-dnsmasq&quot; .</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li><p>进入hadoop-fake目录，执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker build -t=&quot;kdf5000/ubuntu-hadoop&quot; .</span><br></pre></td></tr></table></figure></li><li><p>进入hadoop-hydra目录，执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker build -t=&quot;kdf5000/hadoop-hydra&quot;</span><br></pre></td></tr></table></figure></li></ul><p>#####创建集群<br>进入项目根目录，执行<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$./start-container.sh [num] //num可选，默认为3</span><br></pre></td></tr></table></figure><p></p><p>默认时启动三个容器，一个作为master，两个slave，如果想要启动其他数目的容器，直接在后面添加数目即可</p><p>#####启动hadoop<br>上一步，启动容器之后，回直接进入master的shell交互界面，可以使用下面的命令验证dns和serf服务是否正确<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$serf members</span><br></pre></td></tr></table></figure><p></p><p>如果出现下面的结果说明服务已经正确安装和启动<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@master:~# serf members</span><br><span class="line">master.kdf5000.com  172.17.0.2:7946  alive  </span><br><span class="line">slave1.kdf5000.com  172.17.0.3:7946  alive  </span><br><span class="line">slave2.kdf5000.com  172.17.0.4:7946  alive</span><br></pre></td></tr></table></figure><p></p><p><strong>如果没有出现上面的结果，请仔细检查前面步骤是否有问题，否则下面步骤将不能正确执行</strong></p><p>在master主机进入用户(root)目录，然后执行根目录下的脚本<code>start_service.sh</code>,将启动hadoop集群。<br>使用<code>jps</code>验证是否启动成功，如果在master上出现下面信息说明启动成功<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@master:~# jps</span><br><span class="line">1598 HRegionServer</span><br><span class="line">393 NameNode</span><br><span class="line">909 NodeManager</span><br><span class="line">1415 HQuorumPeer</span><br><span class="line">6209 Jps</span><br><span class="line">666 SecondaryNameNode</span><br><span class="line">515 DataNode</span><br><span class="line">812 ResourceManager</span><br></pre></td></tr></table></figure><p></p><p>使用下面命令进入slave主机，进行同样验证，出现下面信息及说明启动成功<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/# ssh slave1.kdf5000.com</span><br><span class="line">Warning: Permanently added &apos;slave1.kdf5000.com,172.17.0.3&apos; (ECDSA) to the list of known hosts.</span><br><span class="line">Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-85-generic x86_64)</span><br><span class="line"></span><br><span class="line"> * Documentation:  https://help.ubuntu.com/</span><br><span class="line">Last login: Sun May 15 13:29:30 2016 from master.kdf5000.com</span><br><span class="line">root@slave1:~# </span><br><span class="line">root@slave1:~# jps</span><br><span class="line">1853 Jps</span><br><span class="line">293 NodeManager</span><br><span class="line">195 DataNode</span><br></pre></td></tr></table></figure><p></p><p>#####wordcount测试</p><p>进入master主机的用户根目录，执行<code>wordcount.sh</code>脚本，观察执行过程，如果最后输出下面信息说明完全分布式hadoop环境搭建成功<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wordcount output:</span><br><span class="line">16/05/15 14:01:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2	ello</span><br><span class="line">1	ocker</span><br><span class="line">1	adoop</span><br></pre></td></tr></table></figure><p></p><hr><p><strong>参考项目</strong></p><ol><li><p><a href="https://github.com/kiwenlau/hadoop-cluster-docker" target="_blank" rel="noopener">https://github.com/kiwenlau/hadoop-cluster-docker</a></p></li><li><p><a href="https://github.com/alvinhenrick/docker-serf" target="_blank" rel="noopener">https://github.com/alvinhenrick/docker-serf</a></p></li><li><p><a href="https://github.com/alvinhenrick/hadoop-mutinode" target="_blank" rel="noopener">https://github.com/alvinhenrick/hadoop-mutinode</a></p></li></ol><div style="display:none"><script src="http://s4.cnzz.com/stat.php?id=undefined&web_id=undefined" language="JavaScript"></script>script></div><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>